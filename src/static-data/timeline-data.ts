export const timelineData = [
  {
    date: "12/27/2024",
    title: "Terraform-To-Go",
    description:
      "Designed a Terraform IaC boilerplate for rapid infrastructure deployment in passion projects and ad hoc workloads.",
    link: "https://github.com/jcoleharrison",
    tags: ["miscellaneous", "codebase"],
  },
  {
    date: "01/06/2025",
    title: "LeRobot Koch-1 Assembly & Teleoperation",
    description:
      "Assembled the LeRobot Koch-1 robot and implemented teleoperation controls; contributed enhancements to the LeRobot repository.",
    link: "https://x.com/cole__ai/status/1896966389585547734",
    tags: ["embodied ai", "robotics", "prototype"],
  },
  {
    date: "02/16/2025",
    title: "Pippin Autonomous Agent Framework",
    description:
      "Collaborated with Yohei Nakajima on Pippin, the first iteration of a flexible framework for autonomous AI agents.",
    link: "https://github.com/pippinlovesyou/pippin",
    tags: [
      "prototype",
      "ai agents",
      "large language models",
      "miscellaneous",
      "codebase",
    ],
  },
  {
    date: "02/18/2025",
    title: "Alpha Signal Crypto",
    description:
      "Developed a crypto trading platform that uses social signals to anticipate market hype, limit downside risk, and automate profit-taking. Visit: <a href='https://alphasignalcrypto.com'>alphasignalcrypto.com</a>.",
    link: "https://x.com/cole__ai/status/1909371543773126920",
    tags: ["prototype", "miscellaneous", "codebase"],
  },
  {
    date: "03/12/2025",
    title: "AutoGrad from Scratch",
    description:
      "Simple autograd system from scratch in Python to refresh on the mechanics of backprop",
    tags: ["experiment"],
  },
  {
    date: "06/04/2025",
    link: "https://x.com/cole__ai/status/1930336027010331057",
    title: "TimesFM Crypto Price Prediction Fine-Tuning",
    description:
      "Fine-tuned time series foundation model (TimesFM) on crypto price data to integrate Solana price predictions into Alpha Signal.",
    tags: ["prototype", "time series", "fine-tuning"],
  },
  {
    date: "06/08/2025",
    title: "GPT2 from Scratch (Multi-GPU FSDP)",
    description:
      "Implemented GPT2 from the ground up in pytorch: causal transformer language model, tokenizer, optimizer schedules, fully-sharded distributed data parallel (FSDP), mixed precision training, kernel fusion, FlashAttention, gradient clipping & accumulation",
    link: "https://x.com/cole__ai/status/1940906309257150574",
    tags: ["large language models", "experiment"],
  },
  {
    date: "06/20/2025",
    title: "MeGPT",
    link: "https://github.com/jcoleharrison/meGPT",
    description:
      "Train a personalized Llama-based chatbot to speak like you! Fine-tuned on your iMessage history using a QLoRA fine-tuning pipeline, MeGPT adds custom special tokenizer tokens and resizes LLM's LM_head and embedding layers, trains your model, and then deploys your model interface for inference.",
    tags: ["prototype", "large language models", "codebase"],
  },
];
